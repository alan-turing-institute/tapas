"""
In this file, we apply the MIA attack to synthetic networks

"""

import tapas.datasets
import tapas.generators
import tapas.threat_models
import tapas.attacks

# Some fancy displays when training/testing.
import tqdm

print("Loading dataset...")

# tu_dataset = tapas.datasets.TUDataset.download_and_read("DD")
tu_dataset = tapas.datasets.TUDataset.read("DD", "DD")
# tu_dataset = tapas.datasets.TUDataset.download_and_read("ENZYMES")
# tu_dataset = tapas.datasets.TUDataset.download_and_read("MUTAG")
#tu_dataset = tapas.datasets.TUDataset.read("MUTAG", "MUTAG")

# We attack the Rng generator
generator = tapas.generators.network_generator.GNP()

data_knowledge = tapas.threat_models.AuxiliaryDataKnowledge(
    # The attacker has access to 60% of the data as auxiliary information.
    # This information will be used to generate training datasets.
    tu_dataset,
    auxiliary_split=0.6,
    # The attacker knows that the real dataset contains 5000 samples. This thus
    # reflects the attacker's knowledge about the real data.
    num_training_records=450,
)

sdg_knowledge = tapas.threat_models.BlackBoxKnowledge(
    generator,
    # The attacker also specifies the size of the output dataset. In practice,
    # use the size of the published synthetic dataset.
    num_synthetic_records=300,
)

# Now that we have defined the attacker's knowledge, we define their goal.
# We will here focus on a membership inference attack on a random record.
threat_model = tapas.threat_models.TargetedMIA(
    attacker_knowledge_data=data_knowledge,
    # We here select the first record, arbitrarily.
    target_record=tu_dataset.get_records([0]),
    attacker_knowledge_generator=sdg_knowledge,
    # These are mostly technical questions. They inform how the attacker will
    # be trained, but are not impactful changes of the threat model.
    #  - do we generate pairs (D, D U {target}) to train the attack?
    generate_pairs=True,
    #  - do we append the target to the dataset, or replace a record by it?
    replace_target=True,
    # (Optional) nice display for training and testing.
    iterator_tracker=tqdm.tqdm,
)

attacker = tapas.attacks.NetworkMIA()
#attacker = tapas.attacks.NetworkFeatureMIA()

print("Training the attack...")
# Having defined all the objects that we need, we can train the attack.
attacker.train(
    # The TargetedMIA threat model is a TrainableThreatModel: it defines a method
    #  to generate training samples (synthetic_dataset, target_in_real_dataset).
    # This is why the threat model is passed to train the attacker.
    threat_model,
    # This is the number of training pairs generated by the threat model to
    # train the attacker.
    num_samples=100,
)

print("Testing the attack...")
# The attack is trained! Evaluate it within the test model.
# [explain why we split this way.]
attack_summary = threat_model.test(attacker, num_samples=50)

# Output nice, printable metrics that evaluate the attack.
metrics = attack_summary.get_metrics()
print("Results:\n", metrics.head())
